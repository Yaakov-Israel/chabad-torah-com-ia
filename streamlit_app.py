# Bloco 1: InstalaÃ§Ã£o de Pacotes e ConfiguraÃ§Ã£o Inicial (Adaptado para Google Gemini)

# Instala/Atualiza as bibliotecas necessÃ¡rias para tentar resolver conflitos
!pip install -U langchain langchain-google-genai google-generativeai google-ai-generativelanguage google-colab pillow -q

import os
from google.colab import userdata # Para buscar a chave API dos secrets do Colab
import google.generativeai as genai # Importa a SDK do Google GenAI
from langchain_google_genai import ChatGoogleGenerativeAI # Importa o wrapper do LangChain para Gemini
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain

# --- ConfiguraÃ§Ã£o da Chave API do Google usando Colab Secrets ---
# >>>>> CERTIFIQUE-SE QUE ESTA LINHA ABAIXO CONTÃ‰M O NOME EXATO DO SECRET CRIADO NO PASSO 1 <<<<<
NOME_DO_SEU_SECRET_NO_COLAB = 'MINHA_CHAVE_API'
# (Esta linha estÃ¡ PERFEITA, pois o nome do seu secret Ã© 'MINHA_CHAVE_API')

GOOGLE_API_KEY = None # Inicializa como None
print(f"Tentando carregar o secret: '{NOME_DO_SEU_SECRET_NO_COLAB}'...")
try:
    # Aqui ele vai tentar ler o secret com o nome 'MINHA_CHAVE_API'
    GOOGLE_API_KEY = userdata.get(NOME_DO_SEU_SECRET_NO_COLAB)

    # LINHA DE DEPURAÃ‡ÃƒO CRUCIAL:
    print(f"Valor bruto retornado por userdata.get('{NOME_DO_SEU_SECRET_NO_COLAB}'): [{GOOGLE_API_KEY}]")
    # (Precisamos MUITO ver o que esta linha acima vai imprimir quando vocÃª rodar)

    if GOOGLE_API_KEY and GOOGLE_API_KEY.strip(): # Verifica se nÃ£o Ã© None e nÃ£o Ã© uma string vazia/sÃ³ com espaÃ§os
        os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
        genai.configure(api_key=GOOGLE_API_KEY)
        print(f"âœ… Chave API encontrada e configurada a partir do secret '{NOME_DO_SEU_SECRET_NO_COLAB}'.")
    else:
        print(f"âš ï¸ O secret '{NOME_DO_SEU_SECRET_NO_COLAB}' foi encontrado, mas estÃ¡ vazio ou contÃ©m apenas espaÃ§os.")
        GOOGLE_API_KEY = None # Garante que Ã© None se estiver vazio

except userdata.SecretNotFoundError:
    print(f"############################################################################")
    print(f"# ðŸš¨ ATENÃ‡ÃƒO: Secret '{NOME_DO_SEU_SECRET_NO_COLAB}' NÃƒO ENCONTRADO NO COLAB! #")
    print(f"# Verifique na interface de Secrets do Colab (Ã­cone de chave ðŸ”‘) se:          #")
    print(f"# 1. VocÃª criou um secret com o NOME EXATO: '{NOME_DO_SEU_SECRET_NO_COLAB}'.   #")
    print(f"# 2. O campo VALOR deste secret contÃ©m sua chave API (que comeÃ§a com AIzaSy...).#")
    print(f"# 3. A opÃ§Ã£o 'Acesso do notebook' estÃ¡ ATIVADA para este secret.             #")
    print(f"############################################################################")
    GOOGLE_API_KEY = None # Garante que Ã© None se nÃ£o encontrado
except Exception as e:
    print(f"ðŸ˜¥ Ocorreu um erro inesperado ao buscar o secret '{NOME_DO_SEU_SECRET_NO_COLAB}': {e}")
    GOOGLE_API_KEY = None # Garante que Ã© None em outros erros

# Inicializa o modelo LLM (usando Gemini 1.5 Flash)
llm = None
if GOOGLE_API_KEY:
    try:
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash",
                                     temperature=0.7,
                                     convert_system_message_to_human=True)
        print("âœ… Modelo LLM (Google Gemini 1.5 Flash) inicializado com sucesso!")
    except Exception as e:
        print(f"############################################################################")
        print(f"# ðŸ˜¥ ERRO AO INICIALIZAR O MODELO LLM DO GOOGLE: {e}                      #")
        print(f"# Verifique se:                                                            #")
        print(f"# 1. Sua chave API (lida do secret '{NOME_DO_SEU_SECRET_NO_COLAB}') Ã© vÃ¡lida e funcional. #")
        print(f"# 2. A API 'Generative Language API' estÃ¡ ATIVA no seu projeto Google Cloud associado a esta chave.#")
        print(f"# 3. VocÃª tem permissÃµes e/ou cotas suficientes para usar o modelo.        #")
        print(f"############################################################################")
else:
    print(f"âŒ A chave API do Google nÃ£o foi carregada corretamente do secret '{NOME_DO_SEU_SECRET_NO_COLAB}'. O modelo LLM nÃ£o pode ser inicializado.")


# --- DefiniÃ§Ã£o do Super Agente ---
class SuperAgentePequenasEmpresas:
    def __init__(self, llm_model):
        if llm_model is None:
            raise ValueError("Modelo LLM nÃ£o foi inicializado. Verifique a configuraÃ§Ã£o da API Key e os logs acima.")
        self.llm = llm_model
        self.system_message_template = """
        VocÃª Ã© o "IA - Varejo Master", um super especialista em trazer soluÃ§Ãµes inovadoras de IA
        para serem aplicadas em pequenas empresas. Sua comunicaÃ§Ã£o deve ser objetiva, sucinta,
        prÃ¡tica e focada em resolver as dores do usuÃ¡rio.
        """

    def _criar_chain(self, area_especifica_prompt=""):
        prompt_template_msgs = [
            SystemMessagePromptTemplate.from_template(self.system_message_template + "\n" + area_especifica_prompt),
            HumanMessagePromptTemplate.from_template("{solicitacao_usuario}")
        ]
        chat_prompt = ChatPromptTemplate.from_messages(prompt_template_msgs)
        return LLMChain(llm=self.llm, prompt=chat_prompt, verbose=False)

    def responder_pergunta_geral(self, solicitacao_usuario):
        chain = self._criar_chain("Seu foco Ã© fornecer uma visÃ£o geral e conselhos prÃ¡ticos.")
        resposta = chain.run({"solicitacao_usuario": solicitacao_usuario})
        return resposta

    def gestao_financeira(self, solicitacao_usuario):
        prompt_especifico = "Foco Atual: GestÃ£o Financeira. Detalhe aspectos como fluxo de caixa, contas a pagar/receber, e conciliaÃ§Ã£o bancÃ¡ria."
        chain = self._criar_chain(prompt_especifico)
        return chain.run({"solicitacao_usuario": solicitacao_usuario})

    def planejamento_financeiro(self, solicitacao_usuario):
        prompt_especifico = "Foco Atual: Planejamento Financeiro. ForneÃ§a orientaÃ§Ãµes claras, passos prÃ¡ticos e sugestÃµes de ferramentas/templates."
        chain = self._criar_chain(prompt_especifico)
        return chain.run({"solicitacao_usuario": solicitacao_usuario})

    def controle_de_custos(self, solicitacao_usuario):
        prompt_especifico = "Foco Atual: Controle de Custos. Apresente estratÃ©gias para identificar, analisar e reduzir custos fixos e variÃ¡veis."
        chain = self._criar_chain(prompt_especifico)
        return chain.run({"solicitacao_usuario": solicitacao_usuario})

    def precificacao(self, solicitacao_usuario):
        prompt_especifico = "Foco Atual: PrecificaÃ§Ã£o de Produtos/ServiÃ§os. Explique mÃ©todos como markup, margem de contribuiÃ§Ã£o e precificaÃ§Ã£o baseada em valor."
        chain = self._criar_chain(prompt_especifico)
        return chain.run({"solicitacao_usuario": solicitacao_usuario})

    def acesso_a_credito(self, solicit
